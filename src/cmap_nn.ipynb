{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crop Mapping with Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import h5py\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image, ImageEnhance\n",
    "from collections import defaultdict\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import RandomOverSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdf5_path = \"../dataset/dataset_ca_17.hdf5\"\n",
    "image_size = (224, 224)\n",
    "sequence_length = 3\n",
    "sensors = [\"RGB\", \"NDVI45\", \"PSRI\"]\n",
    "crop_mapping = {\n",
    "    \"BARLEY\": 0,\n",
    "    \"CANOLA\": 1,\n",
    "    \"CORN\": 2,\n",
    "    \"MIXEDWOOD\": 3,\n",
    "    \"OAT\": 4,\n",
    "    \"ORCHARD\": 5,\n",
    "    \"PASTURE\": 6,\n",
    "    \"POTATO\": 7,\n",
    "    \"SOYBEAN\": 8,\n",
    "    \"SPRING_WHEAT\": 9,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and Verify Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to decode an image stored as a variable-length uint8 array\n",
    "def decode_image(uint8_array, sensor_type):\n",
    "    if uint8_array.size == 0:\n",
    "        return None\n",
    "    \n",
    "    img_bytes = uint8_array.tobytes()\n",
    "\n",
    "    try:\n",
    "        image = Image.open(io.BytesIO(img_bytes))\n",
    "        # Convert RGB images to full color.\n",
    "        if sensor_type == \"RGB\":\n",
    "            image = image.convert(\"RGB\")\n",
    "        # Other sensor types might be encoded as a single channel\n",
    "        else:\n",
    "            image = image.convert(\"L\")\n",
    "        return image\n",
    "    except Exception as e:\n",
    "        print(f\"Error decoding {sensor_type} image:\", e)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Container for all records\n",
    "records = []\n",
    "\n",
    "with h5py.File(hdf5_path, \"r\") as hf:\n",
    "    # List available datasets for verification\n",
    "    print(\"Datasets available in the HDF5 file:\")\n",
    "    for key in hf.keys():\n",
    "        print(f\"{key}: {hf[key].shape}\")\n",
    "\n",
    "    num_records = hf[\"POINT\"].shape[0]\n",
    "    print(\"\\nTotal number of records:\", num_records)\n",
    "\n",
    "    # Iterate over each record\n",
    "    for idx in range(num_records):\n",
    "        record = {}\n",
    "\n",
    "        date = hf[\"DATE\"][idx]\n",
    "        point = hf[\"POINT\"][idx]\n",
    "        region = hf[\"REGION\"][idx]\n",
    "        label = hf[\"LABEL\"][idx]\n",
    "        \n",
    "        record[\"DATE\"] = date\n",
    "        record[\"POINT\"] = point\n",
    "        record[\"REGION\"] = region\n",
    "        record[\"LABEL\"] = label\n",
    "\n",
    "        # Extract and decode images for each sensor\n",
    "        for sensor in sensors:\n",
    "            sensor_data = hf[sensor][idx]\n",
    "            image = decode_image(sensor_data, sensor)\n",
    "            record[sensor] = image\n",
    "\n",
    "        records.append(record)\n",
    "\n",
    "# Print out details for a randomly selected record\n",
    "selected_record = random.choice(records)\n",
    "print(\"\\nDetails for a randomly selected record:\")\n",
    "print(f\"LABEL: {selected_record['LABEL']}\")\n",
    "print(f\"DATE: {selected_record['DATE']}\")\n",
    "print(f\"POINT: {selected_record['POINT']}\")\n",
    "print(f\"REGION: {selected_record['REGION']}\")\n",
    "for sensor in sensors:\n",
    "    image = selected_record[sensor]\n",
    "    if image is not None:\n",
    "        print(f\"{sensor}: decoded image shape = {image.size}, mode = {image.mode}\")\n",
    "    else:\n",
    "        print(f\"{sensor}: No image data or decoding failed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group Records by Point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points_dict = defaultdict(list)\n",
    "for record in records:\n",
    "    points_dict[record['POINT']].append(record)\n",
    "\n",
    "# Process each point's records to generate sequences\n",
    "sequences = []\n",
    "labels = []\n",
    "points_sequences = []\n",
    "\n",
    "for point, point_records in points_dict.items():\n",
    "    # Sort records by date\n",
    "    point_records_sorted = sorted(point_records, key=lambda x: x['DATE'])\n",
    "    \n",
    "    # Check if all labels are consistent for the point\n",
    "    unique_labels = set(r['LABEL'] for r in point_records_sorted)\n",
    "    if len(unique_labels) != 1:\n",
    "        continue\n",
    "    \n",
    "    # Generate sequences of 3 consecutive records\n",
    "    if len(point_records_sorted) >= 3:\n",
    "        label = point_records_sorted[0]['LABEL']\n",
    "        for i in range(len(point_records_sorted) - 2):\n",
    "            sequences.append(point_records_sorted[i:i+3])\n",
    "            labels.append(label)\n",
    "            points_sequences.append(point)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Train, Validation, and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial point-based split\n",
    "unique_points = list(set(points_sequences))\n",
    "train_points, temp_points = train_test_split(unique_points, test_size=0.3, random_state=42)\n",
    "val_points, test_points = train_test_split(temp_points, test_size=0.5, random_state=42)\n",
    "\n",
    "# Balance training set\n",
    "ros = RandomOverSampler(sampling_strategy='not minority')\n",
    "_, _ = ros.fit_resample(np.array(train_points).reshape(-1, 1), [labels[points_sequences.index(p)] for p in train_points])\n",
    "balanced_train_points = [p[0] for p in ros.sample_indices_]\n",
    "\n",
    "# Create final indices\n",
    "train_indices = [i for i, p in enumerate(points_sequences) if p in balanced_train_points]\n",
    "val_indices = [i for i, p in enumerate(points_sequences) if p in val_points]\n",
    "test_indices = [i for i, p in enumerate(points_sequences) if p in test_points]\n",
    "\n",
    "X_train = [sequences[i] for i in train_indices]\n",
    "y_train = [labels[i] for i in train_indices]\n",
    "X_val = [sequences[i] for i in val_indices]\n",
    "y_val = [labels[i] for i in val_indices]\n",
    "X_test = [sequences[i] for i in test_indices]\n",
    "y_test = [labels[i] for i in test_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_image(img, sensor, label, class_counts):\n",
    "    if sensor == \"RGB\":\n",
    "        # Color augmentations only for RGB\n",
    "        if random.random() < 0.7 * (1 - class_counts[label]/max(class_counts)):\n",
    "            img = ImageEnhance.Color(img).enhance(random.uniform(0.8, 1.2))\n",
    "    # Geometric augmentations for all sensors\n",
    "    if random.random() < 0.5 * (1 - class_counts[label]/max(class_counts)):\n",
    "        img = img.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "    if random.random() < 0.3 * (1 - class_counts[label]/max(class_counts)):\n",
    "        img = img.rotate(random.randint(-15, 15))\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_sequence(sequence, augment=False):\n",
    "    class_counts = np.bincount(y_train)\n",
    "    processed_seq = []\n",
    "    \n",
    "    for record in sequence:\n",
    "        channels = []\n",
    "        for sensor in sensors:\n",
    "            img = record[sensor].copy()\n",
    "            if augment:\n",
    "                img = augment_image(img, sensor, record[\"LABEL\"], class_counts)\n",
    "            img = img.resize(image_size)\n",
    "            \n",
    "            if sensor == \"RGB\":\n",
    "                img_array = np.array(img) / 255.0\n",
    "            else:\n",
    "                img_array = np.array(img.convert(\"L\"))[:, :, np.newaxis] / 255.0\n",
    "                \n",
    "            channels.append(img_array)\n",
    "        \n",
    "        combined = np.concatenate(channels, axis=-1)\n",
    "        processed_seq.append(combined)\n",
    "    \n",
    "    return np.array(processed_seq)\n",
    "\n",
    "# Calculate class weights for reference\n",
    "class_counts = np.bincount(y_train)\n",
    "class_weights = {i: sum(class_counts)/count for i, count in enumerate(class_counts)}\n",
    "\n",
    "# Process datasets\n",
    "X_train_np = np.array([process_sequence(seq, augment=True) for seq in X_train])\n",
    "X_val_np = np.array([process_sequence(seq) for seq in X_val])\n",
    "X_test_np = np.array([process_sequence(seq) for seq in X_test])\n",
    "\n",
    "# Assign labels\n",
    "y_train_np = np.array(y_train)\n",
    "y_val_np = np.array(y_val)\n",
    "y_test_np = np.array(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Final Dataset Shapes:\")\n",
    "print(f\"Train: {X_train_np.shape}, {y_train_np.shape}\")\n",
    "print(f\"Val: {X_val_np.shape}, {y_val_np.shape}\")\n",
    "print(f\"Test: {X_test_np.shape}, {y_test_np.shape}\")\n",
    "\n",
    "print(\"\\nClass Distributions:\")\n",
    "print(f\"Train: {np.unique(y_train_np, return_counts=True)}\")\n",
    "print(f\"Val: {np.unique(y_val_np, return_counts=True)}\")\n",
    "print(f\"Test: {np.unique(y_test_np, return_counts=True)}\")\n",
    "\n",
    "print(\"\\nClass Weights:\", class_weights)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
