{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crop Mapping with Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import h5py\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from PIL import Image, ImageEnhance\n",
    "from collections import defaultdict\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import class_weight\n",
    "from imblearn.over_sampling import RandomOverSampler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset parameters\n",
    "hdf5_path = \"../dataset/dataset_ca_17.hdf5\"\n",
    "image_size = (65, 65)\n",
    "sequence_length = 3\n",
    "sensors = [\"RGB\", \"NDVI45\", \"PSRI\"]\n",
    "crop_mapping = {\n",
    "    \"BARLEY\": 0,\n",
    "    \"CANOLA\": 1,\n",
    "    \"CORN\": 2,\n",
    "    \"MIXEDWOOD\": 3,\n",
    "    \"OAT\": 4,\n",
    "    \"ORCHARD\": 5,\n",
    "    \"PASTURE\": 6,\n",
    "    \"POTATO\": 7,\n",
    "    \"SOYBEAN\": 8,\n",
    "    \"SPRING_WHEAT\": 9,\n",
    "}\n",
    "\n",
    "# Split parameters\n",
    "test_size = 0.3\n",
    "val_size = 0.15\n",
    "\n",
    "# Augmentation parameters\n",
    "batch_size = 32\n",
    "color_prob = 0.7\n",
    "hflip_prob = 0.5\n",
    "rotate_prob = 0.3\n",
    "rotate_range = (-15, 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and Verify Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to decode an image stored as a variable-length uint8 array\n",
    "def decode_image(uint8_array, sensor_type):\n",
    "    if uint8_array.size == 0:\n",
    "        return None\n",
    "\n",
    "    image_bytes = uint8_array.tobytes()\n",
    "\n",
    "    try:\n",
    "        image = Image.open(io.BytesIO(image_bytes))\n",
    "        # Convert RGB images to full color.\n",
    "        if sensor_type == \"RGB\":\n",
    "            image = image.convert(\"RGB\")\n",
    "        # Other sensor types might be encoded as a single channel\n",
    "        else:\n",
    "            image = image.convert(\"L\")\n",
    "        return image\n",
    "    except Exception as e:\n",
    "        print(f\"Error decoding {sensor_type} image:\", e)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator for lazy loading records from HDF5 file\n",
    "def load_records(hdf5_path):\n",
    "    with h5py.File(hdf5_path, \"r\") as hf:\n",
    "        num_records = hf[\"POINT\"].shape[0]\n",
    "        for idx in range(num_records):\n",
    "            record = {\n",
    "                \"DATE\": hf[\"DATE\"][idx],\n",
    "                \"POINT\": hf[\"POINT\"][idx],\n",
    "                \"REGION\": hf[\"REGION\"][idx],\n",
    "                \"LABEL\": hf[\"LABEL\"][idx],\n",
    "            }\n",
    "            for sensor in sensors:\n",
    "                sensor_data = hf[sensor][idx]\n",
    "                record[sensor] = decode_image(sensor_data, sensor)\n",
    "            yield record\n",
    "\n",
    "\n",
    "# Load records with memory-efficient generator\n",
    "records = list(load_records(hdf5_path))\n",
    "\n",
    "# Verification\n",
    "selected_record = random.choice(records)\n",
    "print(\"Selected Record Details:\")\n",
    "print(f\"LABEL: {selected_record['LABEL']}\")\n",
    "for sensor in sensors:\n",
    "    image = selected_record[sensor]\n",
    "    print(f\"{sensor}: {image.size if image else 'Missing'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create temporal sequences grouped by geographic points\n",
    "def create_sequences(records):\n",
    "    points = defaultdict(list)\n",
    "    for record in records:\n",
    "        points[record[\"POINT\"]].append(record)\n",
    "\n",
    "    sequences, labels = [], []\n",
    "    for point_recs in points.values():\n",
    "        point_recs.sort(key=lambda x: x[\"DATE\"])\n",
    "        if len({r[\"LABEL\"] for r in point_recs}) != 1:\n",
    "            continue\n",
    "\n",
    "        label = point_recs[0][\"LABEL\"]\n",
    "        sequences += [point_recs[i:i+sequence_length]\n",
    "                      for i in range(len(point_recs) - sequence_length + 1)]\n",
    "        labels += [label] * (len(point_recs) - sequence_length + 1)\n",
    "\n",
    "    print(f\"Created {len(sequences)} sequences from {len(points)} points\")\n",
    "    return sequences, labels\n",
    "\n",
    "\n",
    "sequences, labels = create_sequences(records)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/validation/test split with balanced oversampling.\n",
    "def split_dataset(sequences, labels):\n",
    "    points = [seq[0][\"POINT\"] for seq in sequences]\n",
    "    unique_points = list(set(points))\n",
    "\n",
    "    # Initial split\n",
    "    train_points, test_points = train_test_split(\n",
    "        unique_points, test_size=test_size, random_state=42)\n",
    "    train_points, val_points = train_test_split(\n",
    "        train_points, test_size=val_size/(1-test_size), random_state=42)\n",
    "\n",
    "    # Oversample training data\n",
    "    train_indices = [i for i, p in enumerate(points) if p in train_points]\n",
    "    ros = RandomOverSampler(sampling_strategy='not minority')\n",
    "    resampled_indices, _ = ros.fit_resample(\n",
    "        np.array(train_indices).reshape(-1, 1), [labels[i] for i in train_indices])\n",
    "\n",
    "    return (\n",
    "        [sequences[i] for i in resampled_indices.flatten()],\n",
    "        [labels[i] for i in resampled_indices.flatten()],\n",
    "        [sequences[i] for i, p in enumerate(points) if p in val_points],\n",
    "        [labels[i] for i, p in enumerate(points) if p in val_points],\n",
    "        [sequences[i] for i, p in enumerate(points) if p in test_points],\n",
    "        [labels[i] for i, p in enumerate(points) if p in test_points]\n",
    "    )\n",
    "\n",
    "\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = split_dataset(\n",
    "    sequences, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply augmentations to an image based on sensor type.\n",
    "def augment_image(image, sensor):\n",
    "    if sensor == \"RGB\" and random.random() < color_prob:\n",
    "        image = ImageEnhance.Color(image).enhance(random.uniform(0.8, 1.2))\n",
    "\n",
    "    if random.random() < hflip_prob:\n",
    "        image = image.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "\n",
    "    if random.random() < rotate_prob:\n",
    "        image = image.rotate(random.randint(*rotate_range))\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert sequence of records to normalized numpy array.\n",
    "def preprocess_sequence(sequence, sensors, image_size, augment=False):\n",
    "    processed = []\n",
    "    for record in sequence:\n",
    "        channels = []\n",
    "        for sensor in sensors:\n",
    "            image = record[sensor].copy()\n",
    "            if augment:\n",
    "                image = augment_image(image, sensor)\n",
    "            image = image.resize(image_size)\n",
    "            image_array = np.array(image) / 255.0\n",
    "            if image_array.ndim == 2:\n",
    "                image_array = np.expand_dims(image_array, axis=-1)\n",
    "            channels.append(image_array)\n",
    "        processed.append(np.concatenate(channels, axis=-1))\n",
    "\n",
    "    return np.array(processed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  TensorFlow Dataset Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tf_dataset(sequences, labels, sensors, image_size, batch_size, augment=False):\n",
    "    def _py_preprocess(seq):\n",
    "        return preprocess_sequence(seq.numpy(), sensors, image_size, augment)\n",
    "\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((sequences, labels))\n",
    "    dataset = dataset.map(\n",
    "        lambda x, y: (tf.py_function(_py_preprocess, [x], tf.float32), y),\n",
    "        num_parallel_calls=tf.data.AUTOTUNE\n",
    "    )\n",
    "    dataset = dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "    return dataset\n",
    "\n",
    "\n",
    "# Create TensorFlow Datasets\n",
    "train_ds = create_tf_dataset(\n",
    "    X_train, y_train, sensors=sensors, image_size=image_size, augment=True, batch_size=batch_size)\n",
    "val_ds = create_tf_dataset(\n",
    "    X_val, y_val, sensors=sensors, image_size=image_size, batch_size=batch_size)\n",
    "test_ds = create_tf_dataset(\n",
    "    X_test, y_test, sensors=sensors, image_size=image_size, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate class weights\n",
    "class_weights = class_weight.compute_class_weight('balanced',\n",
    "                                                  classes=np.unique(y_train),\n",
    "                                                  y=y_train)\n",
    "class_weights = dict(enumerate(class_weights))\n",
    "\n",
    "print(\"Dataset Statistics:\")\n",
    "print(f\"Train: {len(X_train)} samples\")\n",
    "print(f\"Validation: {len(X_val)} samples\")\n",
    "print(f\"Test: {len(X_test)} samples\")\n",
    "print(\"\\nClass Weights:\", class_weights)\n",
    "print(\"\\nSample Input Shape:\", next(iter(train_ds))[0].shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
